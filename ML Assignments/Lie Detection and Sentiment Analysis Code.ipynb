{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW8: Lie Detection and Sentiment Classification with Text Mining\n",
        "## IST 707 Applied Machine Learning\n",
        "\n",
        "**Scenario**: Some people claim that machine learning algorithms can figure out whether a person is lying or not. Do you believe that? To test this claim, we have assembled a collection of customer reviews — some true and some false — on which you are going to test how good Naïve Bayes and SVMs can be for **fake review detection**. This data set also has sentiment label for each review. You will also compare NB and SVMs performance in **sentiment classification**. \n",
        "\n",
        "For both tasks, try different tuning parameters and report the results in a table like the following.\n",
        "\n",
        "Model, Parameter Setting, Accuracy Lie Detection, Precision Lie Detection, Recall Lie Detection, Accuracy Sentiment, Precision Sentiment, Recall Sentiment\n",
        "\n",
        "1.\tExplain the data and the pre-processing steps you took to prepare for each classification task.\n",
        "\n",
        "2.\tExplain your initial parameter tuning strategy — which parameter to tune, to what option, and the theoretical foundation for your choice. Does your strategy help you get better results?\n",
        "\n",
        "3.\tCompare performance differences in sentiment classification and lie detection and tell us which task is harder. Try to explain why one may be harder than the other.\n",
        "Provide your code in a separate script."
      ],
      "metadata": {
        "id": "Fd5WGN_oy4xH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZWVrAtsymDN",
        "outputId": "452c77d8-59f8-4751-b322-f5f4ebdc84f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in the data"
      ],
      "metadata": {
        "id": "KWdsblER6AK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as p\n",
        "df = p.read_csv(\"/content/drive/My Drive/Colab Notebooks/deception-data-converted.csv\")\n",
        "# y = df['sentiment'].values\n",
        "# z = df['lie'].values\n",
        "# X = df['review'].values"
      ],
      "metadata": {
        "id": "v_B_Txjg4WRI"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLwSJZ9B75u0",
        "outputId": "b13a9773-339b-49a8-bba6-9dbd3a0c8ee0"
      },
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleanup"
      ],
      "metadata": {
        "id": "ID_A-nrn-lJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we already removed records that had blanks in all columns\n",
        "# remove records that have blank in review\n",
        "df = df[df['review'] != \"''\"]\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAvbFgnc-VvJ",
        "outputId": "9b4916c2-8b94-4d2c-8495-67cef4cf97e7"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique values in lie and sentiment column\n",
        "print(df['lie'].unique())\n",
        "print(df['sentiment'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2TMUhuW_R4s",
        "outputId": "666fadfe-c2e5-4d6e-da1a-209629a23935"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fake' 'TRUE']\n",
            "['negative' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change values of column lie from fake, TRUE to 0, 1 respectively\n",
        "df.loc[df[\"lie\"] == \"fake\", \"lie\"] = \"fake\"\n",
        "df.loc[df[\"lie\"] == \"TRUE\", \"lie\"] = \"real\"\n",
        "print(df['lie'].unique())\n",
        "# factorize the negative and positive values in sentiment column\n",
        "p.factorize(df.sentiment)\n",
        "print(df['sentiment'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V3JUhMYCzFZ",
        "outputId": "58c28cd6-f5b6-4663-a1de-bbbff46c4064"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fake' 'real']\n",
            "['negative' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to predict sentiment and lie, define x and y parameters\n",
        "y = df['sentiment'].values\n",
        "z = df['lie'].values\n",
        "X = df['review'].values"
      ],
      "metadata": {
        "id": "6ij5iPnzGJ2j"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Classification\n",
        "We will first create models for sentiment classification based on the column \"sentiment\" in the data set."
      ],
      "metadata": {
        "id": "dUxYgm5GCBv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split training and testing data\n",
        "split the data so that 80% of it goes to training data and 20% in testing/validation data set."
      ],
      "metadata": {
        "id": "yFqrYCfNOx2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2022)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "print(X_train[0])\n",
        "print(y_train[0])\n",
        "print(X_test[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_gwXtLzRrSN",
        "outputId": "cc89a15b-9364-4f11-9184-29107d04e468"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72,) (72,) (18,) (18,)\n",
            "'This place was one of the best restaurant I have been. The price is little expensive, but the food and the service is best around the area. I went here with my family, and we ordered 4 dishes. They were all well cooked, and their taste were nicely balanced. Waiters came when we needed them without having to call for them. I would definitely recommend it to everyone visiting this area. '\n",
            "positive\n",
            "'Pastablities is a locally owned restaurant in Syracuse. The food is simple and homey and comforting. Their famous bread is baked daily and the bakery is right next door. The bread is soft and chewy and amazing with their homemade spicy tomato sauce. The paste and cheese that I had was cream and cooked to perfection. '\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Checking"
      ],
      "metadata": {
        "id": "t3l4U5p1dtSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts = True)\n",
        "print(np.asarray((unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvQKAHMldcWN",
        "outputId": "501456cb-a858-406f-b78c-35876733cc23"
      },
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['negative' 'positive']\n",
            " [38 34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training data has well balanced examples of both negative and positive records"
      ],
      "metadata": {
        "id": "jH3rDbYgd1aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueTest, countsTest = np.unique(y_test, return_counts = True)\n",
        "print(np.asarray((uniqueTest, countsTest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls58EQktdxY0",
        "outputId": "87456821-915e-4bc5-f601-3cb12679a2e8"
      },
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['negative' 'positive']\n",
            " [8 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "same as training data set, the test data set also has well balanced distribution of data between negative and positive records"
      ],
      "metadata": {
        "id": "mX1zwTMpeB_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization"
      ],
      "metadata": {
        "id": "tQ-oilO2eP9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# define several commonly used vectorizer setting\n",
        "\n",
        "#  unigram boolean vectorizer\n",
        "unigram_bool_vectorizer = CountVectorizer(encoding = 'latin-1', binary = True, stop_words = 'english')\n",
        "\n",
        "#  unigram term frequency vectorizer\n",
        "unigram_count_vectorizer = CountVectorizer(encoding = 'latin-1', binary = False, stop_words = 'english')\n",
        "\n",
        "#  unigram and bigram term frequency vectorizer\n",
        "gram12_count_vectorizer = CountVectorizer(encoding = 'latin-1', ngram_range = (1,2), stop_words = 'english')\n",
        "\n",
        "#  unigram tfidf vectorizer\n",
        "unigram_tfidf_vectorizer = TfidfVectorizer(encoding = 'latin-1', use_idf = True, stop_words = 'english')\n",
        "\n",
        "#  unigram boolean vectorizer, set minimum document frequency to 5\n",
        "unigram_df_bool_vectorizer = CountVectorizer(encoding = 'latin-1', binary = True, min_df = 5, stop_words = 'english')\n",
        "\n",
        "#  unigram term frequency vectorizer, set minimum document frequency to 5\n",
        "unigram_df_count_vectorizer = CountVectorizer(encoding = 'latin-1', binary = False, min_df = 5, stop_words = 'english')\n",
        "\n",
        "#  unigram and bigram term frequency vectorizer, set minimum document frequency to 5\n",
        "gram12_df_count_vectorizer = CountVectorizer(encoding = 'latin-1', ngram_range = (1,2), min_df = 5, stop_words = 'english')\n",
        "\n",
        "#  unigram tfidf vectorizer, set minimum document frequency to 5\n",
        "unigram_df_tfidf_vectorizer = TfidfVectorizer(encoding = 'latin-1', use_idf = True, min_df = 5, stop_words = 'english')"
      ],
      "metadata": {
        "id": "LfXM23lsd0GC"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "xiGvGNHNTLm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize the training data\n",
        "We'll use TFIDF vectorizer as it not only measures how common a particular word is across all the documents in the corpus but also measures the importance of the word in the corpus."
      ],
      "metadata": {
        "id": "OLzmXe2SnCXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_tfidf_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_tfidf_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxtxj_JcnBh4",
        "outputId": "03c40aa5-9fd4-410f-92f1-9087397fa260"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 1092)\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "1092\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize the test data"
      ],
      "metadata": {
        "id": "5frCjrJi95DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK5yqvKK66FE",
        "outputId": "c1665910-354f-4916-d966-ec8b94ca2c49"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 1092)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create base MNB model"
      ],
      "metadata": {
        "id": "FS13B4xZIbRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the MNB module\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# initialize the MNB model\n",
        "nb_clf = MultinomialNB()\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "nb_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTm-xH-sUx9_",
        "outputId": "8f3782ea-658b-4336-fee1-c79871169439"
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpret a trained MNB model - conditional probs - MNB"
      ],
      "metadata": {
        "id": "QSxvWWaFArUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nb_clf.feature_log_prob_.shape)\n",
        "\n",
        "print(unigram_tfidf_vectorizer.vocabulary_.get('bad'))\n",
        "\n",
        "# for i in range(0,1):\n",
        "print(nb_clf.feature_log_prob_[0][unigram_tfidf_vectorizer.vocabulary_.get('bad')])\n",
        "print(nb_clf.feature_log_prob_[1][unigram_tfidf_vectorizer.vocabulary_.get('bad')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nRcPn3lViMS",
        "outputId": "32eeda8b-6e0d-4849-f188-e8b7ba4302d2"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1092)\n",
            "64\n",
            "-6.387523180454758\n",
            "-7.048689820019229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log ratios of conditional probabilities"
      ],
      "metadata": {
        "id": "YHsM3XR3Bsic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_ratios = []\n",
        "features = unigram_tfidf_vectorizer.get_feature_names_out()\n",
        "neg_cond_prob = nb_clf.feature_log_prob_[0]\n",
        "pos_cond_prob = nb_clf.feature_log_prob_[1]\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  log_ratio = pos_cond_prob[i] - neg_cond_prob[i]\n",
        "  log_ratios.append(log_ratio)\n",
        "\n",
        "ranks = sorted(zip(log_ratios, features))\n",
        "print(ranks[:10])\n",
        "print(ranks[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sPGUGC3BUP0",
        "outputId": "487343c8-0859-4092-faf7-70951a144424"
      },
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-0.8102168010676278, 'pizza'), (-0.7834353342873994, 'terrible'), (-0.7652845567614532, 'minutes'), (-0.7063783539213455, 'come'), (-0.6611666395644713, 'bad'), (-0.6599031764518237, 'worst'), (-0.6422900232267983, 'hour'), (-0.6279548103806665, 'asked'), (-0.6173596015153997, 'took'), (-0.6035462154058928, 'salad')]\n",
            "[(0.5483913054291198, 'restaurants'), (0.5484244569231089, 'japanese'), (0.5808766506126357, 'home'), (0.5903823983260255, 'love'), (0.6044640969303776, 'ate'), (0.6087655778538377, 'friendly'), (0.7144463702695942, 'noodle'), (0.8249334902406913, 'great'), (0.8972803526833353, 'amazing'), (1.1267789246586348, 'best')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The words associated with most positive reviews are at the end so it makes sense that the words in this array are \"best\", \"amazing\", \"great\", etc. Some words in this set don't completely make sense like the word \"japanese\".\n",
        "\n",
        "Most of the words associated with negative reviews also make sense like \"terrible\", \"bad\", \"worst\", etc. But some don't like \"pizza\", \"salad\"."
      ],
      "metadata": {
        "id": "M-aSNCaoCNCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test the MNB Classifier"
      ],
      "metadata": {
        "id": "9FoKJeEkDMsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "nb_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IGv6D1uCANF",
        "outputId": "464d87f8-ab4a-409a-cefb-865760d93284"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the MNB model is about 83.33% accurate."
      ],
      "metadata": {
        "id": "oqZQVeqeDVMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred_mnb = nb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
        "cm_mnb = confusion_matrix(y_test, y_pred_mnb, labels = ['negative', 'positive'])\n",
        "print(cm_mnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHnKbZzDUK6",
        "outputId": "9f62af10-5fa6-4f87-90fa-c6ff4314f7af"
      },
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8 0]\n",
            " [3 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the confusion matrix, the model predicted all records that were negative in reality as negative but it also predicted some records that were positive as negative."
      ],
      "metadata": {
        "id": "KWcpj27hDwDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "print(precision_score(y_test, y_pred_mnb, average = None))\n",
        "print(recall_score(y_test, y_pred_mnb, average = None))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_mnb, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO68UCFFDlDo",
        "outputId": "8be963c5-9782-4453-f795-22c2fec8a3f1"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.72727273 1.        ]\n",
            "[1.  0.7]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      1.00      0.84         8\n",
            "    positive       1.00      0.70      0.82        10\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.86      0.85      0.83        18\n",
            "weighted avg       0.88      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpret the prediction result"
      ],
      "metadata": {
        "id": "iUjNA0yoKgn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## find the calculated posterior probability\n",
        "posterior_probs_mnb = nb_clf.predict_proba(X_test_vec)\n",
        "\n",
        "## find the posterior probabilities for the first test example\n",
        "print(posterior_probs_mnb[0])\n",
        "\n",
        "# find the category prediction for the first test example\n",
        "y_pred_mnb = nb_clf.predict(X_test_vec)\n",
        "print(y_pred_mnb[0])\n",
        "\n",
        "# check the actual label for the first test example\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_k-vQNPET3J",
        "outputId": "c1c92044-acc4-405f-dd06-c68034c47809"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.45957137 0.54042863]\n",
            "positive\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the posterior probability for category 'positive' is the greatest, 0.5404, the prediction should be \"positive\". Because the actual label is also \"positive\", this is a correct prediction."
      ],
      "metadata": {
        "id": "dBmCbrsZKp5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Error Analysis"
      ],
      "metadata": {
        "id": "SkyDbfmmK3E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-k1dSN3KmjZ",
        "outputId": "6e7f4aeb-7c82-4e4f-a7ae-a15f795076a8"
      },
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"pizza\" and \"salad\" are categorized as negative in this model. That seems to be the driving force behind these sentences being classified as negative using this model."
      ],
      "metadata": {
        "id": "YN58Xft8M8n1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypertuning parameters for this model"
      ],
      "metadata": {
        "id": "e-Xmd8LNONAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "wIiGCYi2OYvE"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "  'alpha': np.linspace(0.5, 1.5, 6),\n",
        "  'fit_prior': [True, False],\n",
        "}\n",
        "mnb_grid_clf = GridSearchCV(nb_clf, grid_params)\n",
        "mnb_grid_clf.fit(X_train_vec, y_train)\n",
        "print(\"Best Score: \", mnb_grid_clf.best_score_)\n",
        "print(\"Best Params: \", mnb_grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noulipx9LCPS",
        "outputId": "99cb6698-35e7-41f5-fcd2-9347e4d7b9f3"
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8476190476190476\n",
            "Best Params:  {'alpha': 1.3, 'fit_prior': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypertuning the parameters results in slight increase of accuracy to 84.76%. There's no need to create a tuned MNB model with these parameters because if the tuned model had predicted even 1 additional correct, the accuracy score would 16/18 = 88.89%."
      ],
      "metadata": {
        "id": "OZoYjZDdUUIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNB model with TFIDF vectorizer with min_df = 5"
      ],
      "metadata": {
        "id": "NMOgSqAIXNmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_df_tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_df_tfidf_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_df_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_df_tfidf_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BD8T4tYf1D-",
        "outputId": "fbc9726f-a25a-453b-83be-f647069a2342"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 78)\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39617393 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.30122147 0.27858724 0.         0.\n",
            "  0.         0.         0.         0.26909811 0.         0.\n",
            "  0.         0.         0.13363579 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.28919518 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.23258055\n",
            "  0.         0.         0.         0.1830415  0.         0.\n",
            "  0.         0.3151048  0.13773029 0.         0.         0.\n",
            "  0.         0.19025042 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.         0.         0.         0.30122147\n",
            "  0.         0.         0.         0.17964248 0.         0.        ]]\n",
            "78\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_df_tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOyWQ7ceIw0r",
        "outputId": "fbfd542e-4c33-42f4-86cd-32b6784da539"
      },
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "mnb_clf = MultinomialNB()\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "mnb_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgmeZWIgI2H3",
        "outputId": "107b013f-dac2-48ed-e26e-88351cc08c3e"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_ratios = []\n",
        "features = unigram_df_tfidf_vectorizer.get_feature_names_out()\n",
        "neg_cond_prob = mnb_clf.feature_log_prob_[0]\n",
        "pos_cond_prob = mnb_clf.feature_log_prob_[1]\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  log_ratio = pos_cond_prob[i] - neg_cond_prob[i]\n",
        "  log_ratios.append(log_ratio)\n",
        "\n",
        "ranks = sorted(zip(log_ratios, features))\n",
        "print(ranks[:10])\n",
        "print(ranks[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUmKEW1I219",
        "outputId": "9c3af553-44fe-4617-bf1e-6587f789721a"
      },
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-1.161079557942359, 'terrible'), (-1.0086795339362684, 'took'), (-1.0036700498032936, 'worst'), (-0.9410640400369212, 'minutes'), (-0.8762221260039338, 'come'), (-0.871066617115563, 'asked'), (-0.8381184982965362, 'bad'), (-0.8218380048796323, 'hour'), (-0.8174964767768911, 'came'), (-0.7944447687792451, 'bland')]\n",
            "[(0.70306091055643, 'nice'), (0.7293222320432777, 'ambiance'), (0.7454460265742542, 'ask'), (0.7506860105633626, 'favorite'), (0.7593951820299605, 'fresh'), (0.8197803657217815, 'friendly'), (0.8555591415698571, 'delicious'), (1.2001154288604496, 'great'), (1.4564271783835734, 'amazing'), (1.686170093910997, 'best')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "mnb_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoJDM_JlI9FC",
        "outputId": "bd278066-cc8a-4f3e-faff-2948a87fd90c"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_mnb2 = mnb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
        "cm_mnb2 = confusion_matrix(y_test, y_pred_mnb2, labels = ['negative', 'positive'])\n",
        "print(cm_mnb2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg6nt_8wJAca",
        "outputId": "cc7a60b1-9e33-4f0e-9342-ebcb1dedfb66"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [2 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(y_test, y_pred_mnb2, average = None))\n",
        "print(recall_score(y_test, y_pred_mnb2, average = None))\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_mnb2, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83wJ13pbJFlt",
        "outputId": "42a7121e-3751-46ba-f598-9a637000e6ed"
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77777778 0.88888889]\n",
            "[0.875 0.8  ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.88      0.82         8\n",
            "    positive       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.83      0.84      0.83        18\n",
            "weighted avg       0.84      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb2[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb2[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsxJXZyuJI5C",
        "outputId": "c7da8c21-e0ea-483f-e853-2b539b2e7e29"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Twin Trees Cicero, NY This place is very kid friendly...bring the whole family. Awesome salad bar and high quality dishes and desserts. The price and quality are right!'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "errors: 2\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "  'alpha': np.linspace(0.5, 1.5, 6),\n",
        "  'fit_prior': [True, False],\n",
        "}\n",
        "mnb_grid_clf2 = GridSearchCV(mnb_clf, grid_params)\n",
        "mnb_grid_clf2.fit(X_train_vec, y_train)\n",
        "print(\"Best Score: \", mnb_grid_clf.best_score_)\n",
        "print(\"Best Params: \", mnb_grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuJi9QZjJN49",
        "outputId": "8a8abad0-2671-42c4-a051-f460816e2e32"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8476190476190476\n",
            "Best Params:  {'alpha': 1.3, 'fit_prior': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNB with unigram count vectorizer"
      ],
      "metadata": {
        "id": "n5sPdmrKKyec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_count_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_count_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_count_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PNt3gRpKuxq",
        "outputId": "7e07a656-421f-4c00-c88a-2a99a90e2888"
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 1092)\n",
            "[[0 0 0 ... 0 0 0]]\n",
            "1092\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_count_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eypYNL7jKvB9",
        "outputId": "46fe9355-0d7f-49fb-b0a0-acefda2f1a1c"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 1092)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "cmnb_clf = MultinomialNB()\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "cmnb_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QC2w1rRKvTz",
        "outputId": "d8855814-4882-47b7-f7a2-f3dc4a3231e5"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_ratios = []\n",
        "features = unigram_count_vectorizer.get_feature_names_out()\n",
        "neg_cond_prob = cmnb_clf.feature_log_prob_[0]\n",
        "pos_cond_prob = cmnb_clf.feature_log_prob_[1]\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  log_ratio = pos_cond_prob[i] - neg_cond_prob[i]\n",
        "  log_ratios.append(log_ratio)\n",
        "\n",
        "ranks = sorted(zip(log_ratios, features))\n",
        "print(ranks[:10])\n",
        "print(ranks[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF8azGVfKvkd",
        "outputId": "e8beab87-046b-49e7-966c-0b2015869bb7"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-2.1884184893720144, 'terrible'), (-2.0931083095676897, 'took'), (-1.987747793909863, 'plate'), (-1.987747793909863, 'worst'), (-1.869964758253479, 'asked'), (-1.869964758253479, 'come'), (-1.869964758253479, 'pizza'), (-1.7364333656289572, 'hour'), (-1.7364333656289572, 'tofu'), (-1.636349907071974, 'minutes')]\n",
            "[(1.8189146958604567, 'chocolate'), (1.8189146958604567, 'cream'), (1.8189146958604567, 'flavors'), (1.8189146958604567, 'home'), (1.8189146958604567, 'love'), (1.8189146958604567, 'makes'), (2.0012362526544107, 'noodle'), (2.0012362526544107, 'restaurants'), (2.3297403196264472, 'best'), (2.607372056224727, 'amazing')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "cmnb_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQeYDvWgKv0D",
        "outputId": "76664c78-04ff-4724-c55e-25e668907198"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_mnb3 = cmnb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
        "cm_mnb3 = confusion_matrix(y_test, y_pred_mnb3, labels = ['negative', 'positive'])\n",
        "print(cm_mnb3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz--bqHEKwEy",
        "outputId": "51f55360-0c1b-447e-bc71-3f38ac237a41"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [3 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(y_test, y_pred_mnb3, average = None))\n",
        "print(recall_score(y_test, y_pred_mnb3, average = None))\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_mnb3, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPvABgHjKwl9",
        "outputId": "5ceb2bb0-4c31-4f7e-9e56-6c10e5222fb7"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.66666667 0.77777778]\n",
            "[0.75 0.7 ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.75      0.71         8\n",
            "    positive       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.72      0.72      0.72        18\n",
            "weighted avg       0.73      0.72      0.72        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb3[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb3[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItmfxSXsKw7e",
        "outputId": "3a1f301f-68c7-4f1a-e8f8-c2bea160c835"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "'Usually, I use Yelp to find restaurant. The Yelp would give restaurant \\'stars\\' to divide them into different level. And it has own map to direct you to the right place. This summer, I use it to search a subway shop in New York city, and then it give me a best choice. I followed the map to that store, and then I was surprised. It is a butcher\\'s which sell ham gammon. I can not find any subway in this store. When I asked the shop assistant, he said that you can bought ham to do subway by yourself.'\n",
            "errors: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "  'alpha': np.linspace(0.5, 1.5, 6),\n",
        "  'fit_prior': [True, False],\n",
        "}\n",
        "mnb_grid_clf3 = GridSearchCV(cmnb_clf, grid_params)\n",
        "mnb_grid_clf3.fit(X_train_vec, y_train)\n",
        "print(\"Best Score: \", mnb_grid_clf.best_score_)\n",
        "print(\"Best Params: \", mnb_grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GABR41K2KxNB",
        "outputId": "8ff77e80-3dde-4fad-ac79-4d3664bbdeb0"
      },
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8476190476190476\n",
            "Best Params:  {'alpha': 1.3, 'fit_prior': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "cmnb_clf = MultinomialNB(alpha = 1.3, fit_prior = True)\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "cmnb_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq2VRKLZ8-PQ",
        "outputId": "11748571-3407-4ea5-9025-edbfc0ed043a"
      },
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.3)"
            ]
          },
          "metadata": {},
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_mnb3 = cmnb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
        "cm_mnb3 = confusion_matrix(y_test, y_pred_mnb3, labels = ['negative', 'positive'])\n",
        "print(cm_mnb3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mv7Nj5489_X",
        "outputId": "4c8990fd-0508-44e3-edc6-aad624878239"
      },
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [3 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(y_test, y_pred_mnb3, average = None))\n",
        "print(recall_score(y_test, y_pred_mnb3, average = None))\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_mnb3, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Jww7oi892U",
        "outputId": "a7132710-44c7-4c03-a518-df86b8a35eb3"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.66666667 0.77777778]\n",
            "[0.75 0.7 ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.75      0.71         8\n",
            "    positive       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.72      0.72      0.72        18\n",
            "weighted avg       0.73      0.72      0.72        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "cmnb_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlA3fo7089ul",
        "outputId": "c80b3ad3-6621-4c4b-9cf3-622b133d0994"
      },
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNB model with Count vectorizer with min_df = 5"
      ],
      "metadata": {
        "id": "paPVqcZKMqxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_df_count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_df_count_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_df_count_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_df_count_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31maPmonKxhs",
        "outputId": "a5602f8a-dc3a-4b01-bb2d-37bae484af7f"
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 78)\n",
            "[[0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
            "  0 0 0 1 0 0]]\n",
            "78\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_df_count_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfTyMCmEMv2U",
        "outputId": "7673f4ea-3b6f-4a5b-cb40-161ac50daab6"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "cmnb_clf2 = MultinomialNB()\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "cmnb_clf2.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTdBBL7WMwKh",
        "outputId": "1851b8db-f0ff-4beb-dbe8-aa6dbfc5b3ae"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_ratios = []\n",
        "features = unigram_df_count_vectorizer.get_feature_names_out()\n",
        "neg_cond_prob = cmnb_clf2.feature_log_prob_[0]\n",
        "pos_cond_prob = cmnb_clf2.feature_log_prob_[1]\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  log_ratio = pos_cond_prob[i] - neg_cond_prob[i]\n",
        "  log_ratios.append(log_ratio)\n",
        "\n",
        "ranks = sorted(zip(log_ratios, features))\n",
        "print(ranks[:10])\n",
        "print(ranks[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGE7jS2OMwZ5",
        "outputId": "df73636f-3410-4723-8522-5f93c30c203a"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-2.086861609815842, 'terrible'), (-1.9915514300115174, 'took'), (-1.8861909143536915, 'worst'), (-1.7684078786973076, 'asked'), (-1.7684078786973076, 'come'), (-1.634876486072785, 'hour'), (-1.5347930275158017, 'minutes'), (-1.4807258062455264, 'came'), (-1.480725806245526, 'bland'), (-1.480725806245526, 'said')]\n",
            "[(1.004180843542474, 'sauce'), (1.158331523369732, 'nice'), (1.2273243948566837, 'ambiance'), (1.2273243948566837, 'ask'), (1.2273243948566837, 'recommend'), (1.2918629159942538, 'delicious'), (1.4096459516506386, 'friendly'), (1.5637966314778962, 'great'), (2.431297199182619, 'best'), (2.708928935780899, 'amazing')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "cmnb_clf2.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOrgAlJyMwol",
        "outputId": "472a8899-bef7-4754-a6e5-bc0e03ddcf05"
      },
      "execution_count": 445,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_mnb4 = cmnb_clf2.fit(X_train_vec, y_train).predict(X_test_vec)\n",
        "cm_mnb4 = confusion_matrix(y_test, y_pred_mnb4, labels = ['negative', 'positive'])\n",
        "print(cm_mnb4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWDEJH3uMw7G",
        "outputId": "c9b36a50-d51d-45c0-e167-c56edc9ca2b3"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [2 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(y_test, y_pred_mnb4, average = None))\n",
        "print(recall_score(y_test, y_pred_mnb4, average = None))\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_mnb4, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBn9r9utMxNJ",
        "outputId": "df13277a-2646-47b2-a9a3-6129112436ab"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77777778 0.88888889]\n",
            "[0.875 0.8  ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.88      0.82         8\n",
            "    positive       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.83      0.84      0.83        18\n",
            "weighted avg       0.84      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb4[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb4[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Lx_ceqMxmY",
        "outputId": "6531eeec-b6d2-4334-9f6c-7155dba9be69"
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Twin Trees Cicero, NY This place is very kid friendly...bring the whole family. Awesome salad bar and high quality dishes and desserts. The price and quality are right!'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "errors: 2\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "  'alpha': np.linspace(0.5, 1.5, 6),\n",
        "  'fit_prior': [True, False],\n",
        "}\n",
        "mnb_grid_clf4 = GridSearchCV(cmnb_clf2, grid_params)\n",
        "mnb_grid_clf4.fit(X_train_vec, y_train)\n",
        "print(\"Best Score: \", mnb_grid_clf.best_score_)\n",
        "print(\"Best Params: \", mnb_grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOMY0pG3NG_C",
        "outputId": "17363729-d5fd-47df-ffed-b9b2c96f60b4"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8476190476190476\n",
            "Best Params:  {'alpha': 1.3, 'fit_prior': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "-kkOr_K1N3NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize the training data"
      ],
      "metadata": {
        "id": "mB8LhTYhN6i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_tfidf_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_tfidf_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRekti-N6Da",
        "outputId": "558207a5-0c96-425b-ea2e-961d5c092365"
      },
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 1092)\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "1092\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize the test data"
      ],
      "metadata": {
        "id": "5_QRLigiOTSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuLOlCUHNHM-",
        "outputId": "edcf94f5-6941-4942-f87f-c74d53d6d67a"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 1092)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create base Linear SVC model"
      ],
      "metadata": {
        "id": "QpmPqEQNOdLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the LinearSVC module\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# initialize the LinearSVC model\n",
        "svm_clf = LinearSVC(C = 1)\n",
        "\n",
        "# use the training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwJBRDDBNHgO",
        "outputId": "19d37ace-4400-41ee-feb1-e7ba4fc48870"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1)"
            ]
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Interpret trained linear SVC model"
      ],
      "metadata": {
        "id": "UlvkvpUgOt-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For category \"0\" (negative), get all features and their weights and sort them in increasing order\n",
        "feature_ranks = sorted(zip(svm_clf.coef_[0], unigram_tfidf_vectorizer.get_feature_names_out()))\n",
        "\n",
        "## get the 10 features that are best indicators of negative sentiment (they are at the bottom of the ranked list negative_feature_ranks)\n",
        "negative_10 = feature_ranks[:10]\n",
        "print(\"negative words\")\n",
        "for i in range(0, len(negative_10)):\n",
        "    print(negative_10[i])\n",
        "print()\n",
        "\n",
        "## get 10 features that are best indicators of positive sentiment (they are at the bottom of the ranked list positive_feature_ranks)\n",
        "positive_10 = feature_ranks[-10:]\n",
        "print(\"positive words\")\n",
        "for i in range(0, len(positive_10)):\n",
        "    print(positive_10[i])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--JJIqw9OpMY",
        "outputId": "eba08ba0-2f89-488f-ec26-927acd7f4c6f"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative words\n",
            "(-0.6146373237528078, 'pizza')\n",
            "(-0.5980084064595763, 'bad')\n",
            "(-0.5621639413662503, 'minutes')\n",
            "(-0.5369349518253462, 'terrible')\n",
            "(-0.5235938747638061, 'went')\n",
            "(-0.5228494238897976, 'place')\n",
            "(-0.4545683329849489, 'hour')\n",
            "(-0.44177808619691267, 'plate')\n",
            "(-0.4357298312802893, 'come')\n",
            "(-0.42610117095131894, 'dishes')\n",
            "\n",
            "positive words\n",
            "(0.41058569593921296, 'restaurants')\n",
            "(0.42615085119897744, 'll')\n",
            "(0.43257008569841726, 'ate')\n",
            "(0.43316383147819953, 'noodle')\n",
            "(0.43410087975570016, 'delicious')\n",
            "(0.47987048462611187, 'home')\n",
            "(0.5223060000269993, 'friendly')\n",
            "(0.6965433988617675, 'amazing')\n",
            "(0.7548398963663683, 'great')\n",
            "(1.2255887757819786, 'best')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test the Linear SVC classifier"
      ],
      "metadata": {
        "id": "hHNzTLEPPIPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxvs6XJ5O8-P",
        "outputId": "3a0555f3-df88-444a-c52e-9fcf62a8dbb0"
      },
      "execution_count": 454,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {},
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjcDvl8rPMZi",
        "outputId": "da21b77c-a413-44d3-9ced-f9cedd7a37e5"
      },
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.88      0.78         8\n",
            "    positive       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.79      0.79      0.78        18\n",
            "weighted avg       0.80      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Error Analysis"
      ],
      "metadata": {
        "id": "E3lmi5EUPqtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tw2N-uZPajh",
        "outputId": "3b897833-c91b-4dc6-9c4e-6cc46c7d93ac"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train a base SVC model (not just linear)"
      ],
      "metadata": {
        "id": "6AetaMN0QOGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC()\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNyxX9cuP6ar",
        "outputId": "bb3602ce-00c5-42e8-f088-76ffbc5b1c6d"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test the SVC classifier"
      ],
      "metadata": {
        "id": "3USAm3bsQylg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8VFBBNJQzLq",
        "outputId": "5e73e2db-3abc-42cc-dbcf-a639317a7f66"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1hA80xhQ7we",
        "outputId": "af9161b8-0cd4-40c2-874b-a8f575fe63a7"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8 0]\n",
            " [5 5]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      1.00      0.76         8\n",
            "    positive       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.81      0.75      0.71        18\n",
            "weighted avg       0.83      0.72      0.71        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Error Analysis"
      ],
      "metadata": {
        "id": "q9ArwytPRC68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NE5PWu8Q-30",
        "outputId": "3cad9336-fc63-4a0e-9b83-db2cc1f120bc"
      },
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "errors: 0\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Pastablities is a locally owned restaurant in Syracuse. The food is simple and homey and comforting. Their famous bread is baked daily and the bakery is right next door. The bread is soft and chewy and amazing with their homemade spicy tomato sauce. The paste and cheese that I had was cream and cooked to perfection. '\n",
            "'I went into the restaurant, it decorated comfortably with a soft light and nice pictures, the waitress was kind and stand by my side throughout the whole dining time, asking whether I need something more and kept smiling. '\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tuning the SVC model"
      ],
      "metadata": {
        "id": "my9Bn5CFR3T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of possible parameters\n",
        "params_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel':['linear','rbf', 'poly'] }\n",
        "# Create the GridSearchCV object\n",
        "grid_clf = GridSearchCV(svm_clf, params_grid)\n",
        "print(grid_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu5z6mxBRxBk",
        "outputId": "f7fe78d7-104e-4cf3-9932-fe0c97de87ac"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
            "                         'kernel': ['linear', 'rbf', 'poly']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the data with the best possible parameters\n",
        "grid_clf = grid_clf.fit(X_train_vec, y_train)\n",
        "# print the best estimator with it's parameters\n",
        "# print(grid_clf.best_params_)\n",
        "print(\"Best Score: \", grid_clf.best_score_)\n",
        "print(\"Best Params: \", grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vMzM_kzR9vQ",
        "outputId": "90f01646-3bed-4d43-8082-6ab1454f9dfb"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8619047619047618\n",
            "Best Params:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a tuned SVC model"
      ],
      "metadata": {
        "id": "KUtBk-RfSYbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC(C = 1, gamma = 0.0001, kernel = 'linear')\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOiwjsrNSRkK",
        "outputId": "a2a9e3fa-8ea5-4e01-9213-c385e7aacaa1"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, gamma=0.0001, kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test the tuned SVC classifier"
      ],
      "metadata": {
        "id": "_9NNQZTZSvFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQP3hpsSrXV",
        "outputId": "31fbb376-ae8f-42e2-c289-6b4d8f748e4d"
      },
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {},
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfL3ANyDSzXN",
        "outputId": "d60f116d-a80d-4d7f-bb76-6afd46b03f06"
      },
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.88      0.78         8\n",
            "    positive       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.79      0.79      0.78        18\n",
            "weighted avg       0.80      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Error Analysis"
      ],
      "metadata": {
        "id": "4HmbLk70TC5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alh4jsj7S-Ui",
        "outputId": "2c13fb4a-8f67-4211-a6f4-f3973f67d686"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVC model with tfidf vectorizer with min_df = 5"
      ],
      "metadata": {
        "id": "gnoWwOfDT9Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_df_tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbJOzWqLT3S7",
        "outputId": "3a942a09-8c99-48c8-c9dd-563e364f4e2d"
      },
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_df_tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_df_tfidf_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_df_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_df_tfidf_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piTZ39w-UN3l",
        "outputId": "05d19213-7bbb-448f-d820-633de0a8123d"
      },
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 78)\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39617393 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.30122147 0.27858724 0.         0.\n",
            "  0.         0.         0.         0.26909811 0.         0.\n",
            "  0.         0.         0.13363579 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.28919518 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.23258055\n",
            "  0.         0.         0.         0.1830415  0.         0.\n",
            "  0.         0.3151048  0.13773029 0.         0.         0.\n",
            "  0.         0.19025042 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.         0.         0.         0.30122147\n",
            "  0.         0.         0.         0.17964248 0.         0.        ]]\n",
            "78\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC()\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C-WpJB-UZ83",
        "outputId": "4b28084b-d629-43c0-9e34-7c3430ed67c8"
      },
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 469
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvxRdrdIVSUH",
        "outputId": "f3c1de8a-4432-4efb-8c2d-491b59d97b1e"
      },
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {},
          "execution_count": 470
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLGWSbJQVZBV",
        "outputId": "6e5ef043-a61a-4991-8cb0-51011ad15a76"
      },
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.88      0.78         8\n",
            "    positive       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.79      0.79      0.78        18\n",
            "weighted avg       0.80      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zo4gjo0VgKv",
        "outputId": "8df839ac-a23b-4eda-eba5-15f20be96b5a"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Twin Trees Cicero, NY This place is very kid friendly...bring the whole family. Awesome salad bar and high quality dishes and desserts. The price and quality are right!'\n",
            "'I went into the restaurant, it decorated comfortably with a soft light and nice pictures, the waitress was kind and stand by my side throughout the whole dining time, asking whether I need something more and kept smiling. '\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "errors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of possible parameters\n",
        "params_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel':['linear','rbf', 'poly'] }\n",
        "# Create the GridSearchCV object\n",
        "grid_clf = GridSearchCV(svm_clf, params_grid)\n",
        "print(grid_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90PsmUPGVmHs",
        "outputId": "3d907875-1611-42d3-c55a-3bb6e5b4647e"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
            "                         'kernel': ['linear', 'rbf', 'poly']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the data with the best possible parameters\n",
        "grid_clf = grid_clf.fit(X_train_vec, y_train)\n",
        "# print the best estimator with it's parameters\n",
        "# print(grid_clf.best_params_)\n",
        "print(\"Best Score: \", grid_clf.best_score_)\n",
        "print(\"Best Params: \", grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5pnXKCWVuWr",
        "outputId": "a7a89684-ec8b-409d-8742-37a25c70009f"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.7942857142857143\n",
            "Best Params:  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC(C = 1, gamma = 1, kernel = 'rbf')\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8AvbOJkVzgC",
        "outputId": "1608ba5f-dc51-4c0a-a96a-46ac34f3e9f3"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, gamma=1)"
            ]
          },
          "metadata": {},
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhVzwbWtWCt7",
        "outputId": "8e974205-a935-4df4-c0dc-b62371439f69"
      },
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {},
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hf_hg9dWGn5",
        "outputId": "b05dd501-9dcd-43d2-d284-fa12d428f2a3"
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 1]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.88      0.78         8\n",
            "    positive       0.88      0.70      0.78        10\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.79      0.79      0.78        18\n",
            "weighted avg       0.80      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTAujINqWRVU",
        "outputId": "2dbbbe79-e305-4a70-85c2-06cde85eb7df"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "errors: 1\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Twin Trees Cicero, NY This place is very kid friendly...bring the whole family. Awesome salad bar and high quality dishes and desserts. The price and quality are right!'\n",
            "'I went into the restaurant, it decorated comfortably with a soft light and nice pictures, the waitress was kind and stand by my side throughout the whole dining time, asking whether I need something more and kept smiling. '\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "errors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVC model with count vextorizer with min_df = 5"
      ],
      "metadata": {
        "id": "STrvbXTGXoiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = unigram_df_count_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLfHmtJdWgtT",
        "outputId": "a49d92e9-8cab-4a8f-9543-5775348e18af"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_df_count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_df_count_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_df_count_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_df_count_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSqU7-UhY1Fl",
        "outputId": "10acc1c8-a79b-447c-862a-e92d1a25837b"
      },
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 78)\n",
            "[[0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
            "  0 0 0 1 0 0]]\n",
            "78\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC()\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIGKuQ_Qaabr",
        "outputId": "868d3630-6fa7-4625-b82a-7d622fda617d"
      },
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKW5OfmaafnC",
        "outputId": "afb558c2-bb51-41ce-8a6b-935bce7f02da"
      },
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9a-HA9Aakrx",
        "outputId": "01fb40e9-c576-4fe8-ceba-0f78efbc36d1"
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [4 6]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.60      0.75      0.67         8\n",
            "    positive       0.75      0.60      0.67        10\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.68      0.68      0.67        18\n",
            "weighted avg       0.68      0.67      0.67        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of possible parameters\n",
        "params_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel':['linear','rbf', 'poly'] }\n",
        "# Create the GridSearchCV object\n",
        "grid_clf = GridSearchCV(svm_clf, params_grid)\n",
        "print(grid_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTC89SOtJrNk",
        "outputId": "5e31b50d-bde2-4975-f1ad-c25a6ddb3a0f"
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
            "                         'kernel': ['linear', 'rbf', 'poly']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the data with the best possible parameters\n",
        "grid_clf = grid_clf.fit(X_train_vec, y_train)\n",
        "# print the best estimator with it's parameters\n",
        "# print(grid_clf.best_params_)\n",
        "print(\"Best Score: \", grid_clf.best_score_)\n",
        "print(\"Best Params: \", grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUMgB1K9as69",
        "outputId": "83660074-e368-4b31-8a72-de20d5de8baa"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.7638095238095237\n",
            "Best Params:  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC(C = 10, gamma = 0.001, kernel = 'rbf')\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckKgwzMSax5-",
        "outputId": "db51908d-5bbb-424e-abe2-d924259e1a50"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, gamma=0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJrvXQnHbPmZ",
        "outputId": "cceb43b5-c305-421a-ce08-ffe6c90e20b7"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_5ndjfpdHr",
        "outputId": "bcc9081b-e8c7-4ba8-821a-36b9f8e46277"
      },
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.75      0.71         8\n",
            "    positive       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.72      0.72      0.72        18\n",
            "weighted avg       0.73      0.72      0.72        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 3 such examples\n",
        "print(\"SVM error analysis\")\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_svm[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "print()\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 1 such examples\n",
        "# print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_svm[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKYIrxxAphLe",
        "outputId": "c8197381-4233-4f41-b9b6-595ac42bdb05"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM error analysis\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "'Olive Oil Garden was very disappointing. I expect good food and good service (at least!!) when I go out to eat. The meal was cold when we got it, and the waitor had no manners whatsoever. Don\\'t go to the Olive Oil Garden. '\n",
            "'Usually, I use Yelp to find restaurant. The Yelp would give restaurant \\'stars\\' to divide them into different level. And it has own map to direct you to the right place. This summer, I use it to search a subway shop in New York city, and then it give me a best choice. I followed the map to that store, and then I was surprised. It is a butcher\\'s which sell ham gammon. I can not find any subway in this store. When I asked the shop assistant, he said that you can bought ham to do subway by yourself.'\n",
            "errors: 2\n",
            "\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'Twin Trees Cicero, NY This place is very kid friendly...bring the whole family. Awesome salad bar and high quality dishes and desserts. The price and quality are right!'\n",
            "'I went into the restaurant, it decorated comfortably with a soft light and nice pictures, the waitress was kind and stand by my side throughout the whole dining time, asking whether I need something more and kept smiling. '\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "errors: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM with Count Vectorizer"
      ],
      "metadata": {
        "id": "TYwwlzJmKFot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_vec.shape)\n",
        "print(X_train_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_count_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_count_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_count_vectorizer.vocabulary_.get('cooked'))\n",
        "\n",
        "X_test_vec = unigram_count_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqBDxgjDKJ3a",
        "outputId": "945cf69b-1a40-452e-e484-bb431bfbff7c"
      },
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 1092)\n",
            "[[0 0 0 ... 0 0 0]]\n",
            "1092\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "223\n",
            "(18, 1092)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC()\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyHTpVdZKJsF",
        "outputId": "16bfbfc0-20e0-48b1-e1f5-530aafd6f7de"
      },
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 490
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xna2fsfxKJMc",
        "outputId": "ac87e350-a0f4-4702-8724-258e36cf3839"
      },
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 491
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y82PsIcWKJCi",
        "outputId": "a7f39f32-db6f-4b32-8856-ece19a72e66d"
      },
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 4]\n",
            " [2 8]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.50      0.57         8\n",
            "    positive       0.67      0.80      0.73        10\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.67      0.65      0.65        18\n",
            "weighted avg       0.67      0.67      0.66        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of possible parameters\n",
        "params_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel':['linear','rbf', 'poly'] }\n",
        "# Create the GridSearchCV object\n",
        "grid_clf = GridSearchCV(svm_clf, params_grid)\n",
        "print(grid_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ClMooUmKIrP",
        "outputId": "ff9b8016-325c-423b-8518-da343f4785cc"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
            "                         'kernel': ['linear', 'rbf', 'poly']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the data with the best possible parameters\n",
        "grid_clf = grid_clf.fit(X_train_vec, y_train)\n",
        "# print the best estimator with it's parameters\n",
        "# print(grid_clf.best_params_)\n",
        "print(\"Best Score: \", grid_clf.best_score_)\n",
        "print(\"Best Params: \", grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gATWeTEjKIch",
        "outputId": "af3e3390-ba29-4bab-e6dc-fc2dd32a1ecf"
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score:  0.8209523809523811\n",
            "Best Params:  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# initialize the SVC model\n",
        "svm_clf = SVC(C = 0.1, gamma = 0.0001, kernel = 'linear')\n",
        "\n",
        "# use training data to train the model\n",
        "svm_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# get the accuracy of the base SVM classifier\n",
        "# svm_clf_accuracy = svm_clf.score(X_test, y_test)\n",
        "# print(svm_clf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApRCzKVuKqxJ",
        "outputId": "4c7a01ff-6ab5-4bda-cce5-0648a89270a8"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.1, gamma=0.0001, kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "svm_clf.score(X_test_vec, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYF8YTzcLIgI",
        "outputId": "acbc795e-a0b8-4ecc-930a-53eed269957a"
      },
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix and classification report\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "y_pred_svm = svm_clf.predict(X_test_vec)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels = ['negative', 'positive'])\n",
        "print(cm_svm)\n",
        "print()\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['negative','positive']\n",
        "print(classification_report(y_test, y_pred_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHPulTBbLLm0",
        "outputId": "3f9a7845-f63c-41ea-efd3-2a936c9deeb6"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [3 7]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.75      0.71         8\n",
            "    positive       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.72      0.72      0.72        18\n",
            "weighted avg       0.73      0.72      0.72        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fake Review Detection"
      ],
      "metadata": {
        "id": "87y4wIteprg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2, random_state = 2022)\n",
        "\n",
        "print(X_train.shape, z_train.shape, X_test.shape, z_test.shape)\n",
        "print(X_train[0])\n",
        "print(z_train[0])\n",
        "print(X_test[0])\n",
        "print(z_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ip_Hwk8ZlU",
        "outputId": "9be9c5a4-d98b-40cb-c85f-7698f93a046e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72,) (72,) (18,) (18,)\n",
            "'This place was one of the best restaurant I have been. The price is little expensive, but the food and the service is best around the area. I went here with my family, and we ordered 4 dishes. They were all well cooked, and their taste were nicely balanced. Waiters came when we needed them without having to call for them. I would definitely recommend it to everyone visiting this area. '\n",
            "fake\n",
            "'Pastablities is a locally owned restaurant in Syracuse. The food is simple and homey and comforting. Their famous bread is baked daily and the bakery is right next door. The bread is soft and chewy and amazing with their homemade spicy tomato sauce. The paste and cheese that I had was cream and cooked to perfection. '\n",
            "true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Checking"
      ],
      "metadata": {
        "id": "MkCmvCfM9NBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(z_train, return_counts = True)\n",
        "print(np.asarray((unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK4hl0N08nHP",
        "outputId": "89278eb2-7f3f-431c-c0f3-317afae41f2e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['fake' 'true']\n",
            " [36 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training data set is well balanced as it has 36 records in each category true and false."
      ],
      "metadata": {
        "id": "HuBttXGc9v6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueTest, countsTest = np.unique(z_test, return_counts = True)\n",
        "print(np.asarray((uniqueTest, countsTest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHcG12IBplZF",
        "outputId": "ad9356f4-7696-43dc-f261-0c5ed5fa0616"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['fake' 'true']\n",
            " [10 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize train data"
      ],
      "metadata": {
        "id": "_p2v4KQKDdPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit vocabulary in training documents and transform the training documents into vectors\n",
        "X_train_tfidf_vec = unigram_tfidf_vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf_df_vec = unigram_df_tfidf_vectorizer.fit_transform(X_train)\n",
        "X_train_count_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
        "X_train_count_df_vec = unigram_df_count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# check the content of a document vector\n",
        "print(X_train_tfidf_vec.shape)\n",
        "print(X_train_tfidf_vec[0].toarray())\n",
        "print(X_train_tfidf_df_vec.shape)\n",
        "print(X_train_tfidf_df_vec[0].toarray())\n",
        "print(X_train_count_vec.shape)\n",
        "print(X_train_count_vec[0].toarray())\n",
        "print(X_train_count_df_vec.shape)\n",
        "print(X_train_count_df_vec[0].toarray())\n",
        "\n",
        "# check the size of the constructed vocabulary\n",
        "print(len(unigram_tfidf_vectorizer.vocabulary_))\n",
        "print(len(unigram_df_tfidf_vectorizer.vocabulary_))\n",
        "print(len(unigram_count_vectorizer.vocabulary_))\n",
        "print(len(unigram_df_count_vectorizer.vocabulary_))\n",
        "\n",
        "# print out the first 10 items in the vocabulary\n",
        "print(list(unigram_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "print(list(unigram_df_tfidf_vectorizer.vocabulary_.items())[:10])\n",
        "print(list(unigram_count_vectorizer.vocabulary_.items())[:10])\n",
        "print(list(unigram_df_count_vectorizer.vocabulary_.items())[:10])\n",
        "\n",
        "# check word index in vocabulary\n",
        "print(unigram_tfidf_vectorizer.vocabulary_.get('cooked'))\n",
        "print(unigram_df_tfidf_vectorizer.vocabulary_.get('cooked'))\n",
        "print(unigram_count_vectorizer.vocabulary_.get('cooked'))\n",
        "print(unigram_df_count_vectorizer.vocabulary_.get('cooked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2NfZ3pMp8bh",
        "outputId": "454cbf62-a5d9-4b26-d688-5e3f6cf68523"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 1092)\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "(72, 78)\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.39617393 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.30122147 0.27858724 0.         0.\n",
            "  0.         0.         0.         0.26909811 0.         0.\n",
            "  0.         0.         0.13363579 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.28919518 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.23258055\n",
            "  0.         0.         0.         0.1830415  0.         0.\n",
            "  0.         0.3151048  0.13773029 0.         0.         0.\n",
            "  0.         0.19025042 0.         0.         0.26051415 0.\n",
            "  0.         0.         0.         0.         0.         0.30122147\n",
            "  0.         0.         0.         0.17964248 0.         0.        ]]\n",
            "(72, 1092)\n",
            "[[0 0 0 ... 0 0 0]]\n",
            "(72, 78)\n",
            "[[0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
            "  0 0 0 1 0 0]]\n",
            "1092\n",
            "78\n",
            "1092\n",
            "78\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "[('place', 693), ('best', 88), ('restaurant', 778), ('price', 721), ('little', 553), ('expensive', 348), ('food', 392), ('service', 833), ('area', 41), ('went', 1060)]\n",
            "[('place', 51), ('best', 7), ('restaurant', 56), ('little', 39), ('food', 26), ('service', 61), ('went', 75), ('ordered', 47), ('dishes', 21), ('cooked', 14)]\n",
            "223\n",
            "14\n",
            "223\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorize test data"
      ],
      "metadata": {
        "id": "e-KMgsnYDjTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_count_df_vec = unigram_df_count_vectorizer.transform(X_test)\n",
        "X_test_count_vec = unigram_count_vectorizer.transform(X_test)\n",
        "X_test_tfidf_vec = unigram_tfidf_vectorizer.transform(X_test)\n",
        "X_test_tfidf_df_vec = unigram_df_tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# print out #examples and #features in the test set\n",
        "print(X_test_count_df_vec.shape)\n",
        "print(X_test_count_vec.shape)\n",
        "print(X_test_tfidf_vec.shape)\n",
        "print(X_test_tfidf_df_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YygiCKynp8s4",
        "outputId": "485acbdd-abd6-4a06-afa1-278a853b7c05"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18, 78)\n",
            "(18, 1092)\n",
            "(18, 1092)\n",
            "(18, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNB"
      ],
      "metadata": {
        "id": "W5cBXfx8p2-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "count_nb_clf = MultinomialNB()\n",
        "tfidf_nb_clf = MultinomialNB()\n",
        "count_df_nb_clf = MultinomialNB()\n",
        "tfidf_df_nb_clf = MultinomialNB()\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "count_nb_clf.fit(X_train_count_vec, z_train)\n",
        "count_df_nb_clf.fit(X_train_count_df_vec, z_train)\n",
        "tfidf_nb_clf.fit(X_train_tfidf_vec, z_train)\n",
        "tfidf_df_nb_clf.fit(X_train_tfidf_df_vec, z_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlA8pU8Cp89y",
        "outputId": "3dd03b55-24a6-4e6d-a409-39812c541a31"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test the MNB classifier"
      ],
      "metadata": {
        "id": "8Rw0JOJgAF8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "print(count_nb_clf.score(X_test_count_vec, z_test))\n",
        "print(count_df_nb_clf.score(X_test_count_df_vec, z_test))\n",
        "print(tfidf_nb_clf.score(X_test_tfidf_vec, z_test))\n",
        "print(tfidf_df_nb_clf.score(X_test_tfidf_df_vec, z_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH_mc3n0p-gA",
        "outputId": "af1fd95a-04d8-4703-bdba-6491b9493df1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5555555555555556\n",
            "0.5555555555555556\n",
            "0.5555555555555556\n",
            "0.5555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "z_pred_count_mnb = count_nb_clf.fit(X_train_count_vec, z_train).predict(X_test_count_vec)\n",
        "z_pred_tfidf_mnb = tfidf_nb_clf.fit(X_train_tfidf_vec, z_train).predict(X_test_tfidf_vec)\n",
        "z_pred_count_df_mnb = count_df_nb_clf.fit(X_train_count_df_vec, z_train).predict(X_test_count_df_vec)\n",
        "z_pred_tfidf_df_mnb = tfidf_df_nb_clf.fit(X_train_tfidf_df_vec, z_train).predict(X_test_tfidf_df_vec)\n",
        "count_cm_mnb = confusion_matrix(z_test, z_pred_count_mnb, labels = ['fake', 'real'])\n",
        "count_df_cm_mnb = confusion_matrix(z_test, z_pred_count_df_mnb, labels = ['fake', 'real'])\n",
        "tfidf_cm_mnb = confusion_matrix(z_test, z_pred_tfidf_mnb, labels = ['fake', 'real'])\n",
        "tfidf_df_cm_mnb = confusion_matrix(z_test, z_pred_tfidf_df_mnb, labels = ['fake', 'real'])\n",
        "print(count_cm_mnb)\n",
        "print(count_df_cm_mnb)\n",
        "print(tfidf_cm_mnb)\n",
        "print(tfidf_df_cm_mnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsZsm8A-p-ZA",
        "outputId": "100cc172-6720-497b-d45a-796774841092"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5 5]\n",
            " [3 5]]\n",
            "[[4 6]\n",
            " [2 6]]\n",
            "[[5 5]\n",
            " [3 5]]\n",
            "[[5 5]\n",
            " [3 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(z_test, z_pred_count_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_count_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_count_df_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_count_df_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_df_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_df_mnb, average = None))\n",
        "print()\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['fake', 'real']\n",
        "print(classification_report(z_test, z_pred_count_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_count_df_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_df_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_mnb, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yntpJH3Dp-RV",
        "outputId": "6071f251-b1a2-40c6-aa52-85f779f8acf9"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "[0.66666667 0.5       ]\n",
            "[0.4  0.75]\n",
            "\n",
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.40      0.50        10\n",
            "        true       0.50      0.75      0.60         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.58      0.57      0.55        18\n",
            "weighted avg       0.59      0.56      0.54        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Error Analysis"
      ],
      "metadata": {
        "id": "4UpjY3aYO8Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wV0whaZp-Jb",
        "outputId": "2b946bed-60fc-4812-af53-089964415dfc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Hypertuning parameters"
      ],
      "metadata": {
        "id": "-X-9vDYTO_MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {\n",
        "  'alpha': np.linspace(0.5, 1.5, 6),\n",
        "  'fit_prior': [True, False],\n",
        "}\n",
        "mnb_count_grid_clf = GridSearchCV(count_nb_clf, grid_params)\n",
        "mnb_count_grid_clf.fit(X_train_count_vec, z_train)\n",
        "print(\"Best Score Count: \", mnb_count_grid_clf.best_score_)\n",
        "print(\"Best Params Count: \", mnb_count_grid_clf.best_params_)\n",
        "print()\n",
        "mnb_tfidf_grid_clf = GridSearchCV(tfidf_nb_clf, grid_params)\n",
        "mnb_tfidf_grid_clf.fit(X_train_tfidf_vec, z_train)\n",
        "print(\"Best Score tfidf: \", mnb_tfidf_grid_clf.best_score_)\n",
        "print(\"Best Params tfidf: \", mnb_tfidf_grid_clf.best_params_)\n",
        "print()\n",
        "mnb_count_df_grid_clf = GridSearchCV(count_df_nb_clf, grid_params)\n",
        "mnb_count_df_grid_clf.fit(X_train_count_df_vec, z_train)\n",
        "print(\"Best Score Count df: \", mnb_count_df_grid_clf.best_score_)\n",
        "print(\"Best Params Count df: \", mnb_count_df_grid_clf.best_params_)\n",
        "print()\n",
        "mnb_tfidf_df_grid_clf = GridSearchCV(tfidf_df_nb_clf, grid_params)\n",
        "mnb_tfidf_df_grid_clf.fit(X_train_tfidf_df_vec, z_train)\n",
        "print(\"Best Score Count: \", mnb_tfidf_df_grid_clf.best_score_)\n",
        "print(\"Best Params Count: \", mnb_tfidf_df_grid_clf.best_params_)\n",
        "# print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Pymsjnp-AD",
        "outputId": "21b6654a-20e3-4aff-b7b2-491fb1127fbd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score Count:  0.5028571428571429\n",
            "Best Params Count:  {'alpha': 1.1, 'fit_prior': True}\n",
            "\n",
            "Best Score tfidf:  0.5028571428571429\n",
            "Best Params tfidf:  {'alpha': 0.5, 'fit_prior': True}\n",
            "\n",
            "Best Score Count df:  0.47333333333333333\n",
            "Best Params Count df:  {'alpha': 1.3, 'fit_prior': True}\n",
            "\n",
            "Best Score Count:  0.4447619047619048\n",
            "Best Params Count:  {'alpha': 0.5, 'fit_prior': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create and test tuned models"
      ],
      "metadata": {
        "id": "d8-HjLvoRvdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the MNB model\n",
        "tuned_count_nb_clf = MultinomialNB(alpha = 1.1, fit_prior = True)\n",
        "tuned_tfidf_nb_clf = MultinomialNB(alpha = 0.5, fit_prior = True)\n",
        "tuned_count_df_nb_clf = MultinomialNB(alpha = 1.3, fit_prior = True)\n",
        "tuned_tfidf_df_nb_clf = MultinomialNB(alpha = 0.5, fit_prior = True)\n",
        "\n",
        "# use the training data to train the MNB model\n",
        "tuned_count_nb_clf.fit(X_train_count_vec, z_train)\n",
        "tuned_count_df_nb_clf.fit(X_train_count_df_vec, z_train)\n",
        "tuned_tfidf_nb_clf.fit(X_train_tfidf_vec, z_train)\n",
        "tuned_tfidf_df_nb_clf.fit(X_train_tfidf_df_vec, z_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6MgmZU2p92D",
        "outputId": "a5bef28e-ad52-46ba-bd25-fe343f2403ea"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "print(tuned_count_nb_clf.score(X_test_count_vec, z_test))\n",
        "print(tuned_count_df_nb_clf.score(X_test_count_df_vec, z_test))\n",
        "print(tuned_tfidf_nb_clf.score(X_test_tfidf_vec, z_test))\n",
        "print(tuned_tfidf_df_nb_clf.score(X_test_tfidf_df_vec, z_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwFC12Qip9rG",
        "outputId": "074f51d1-fe88-4118-a3ad-c3cd45629cdf"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5555555555555556\n",
            "0.5555555555555556\n",
            "0.5555555555555556\n",
            "0.5555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "z_pred_count_mnb = tuned_count_nb_clf.fit(X_train_count_vec, z_train).predict(X_test_count_vec)\n",
        "z_pred_tfidf_mnb = tuned_tfidf_nb_clf.fit(X_train_tfidf_vec, z_train).predict(X_test_tfidf_vec)\n",
        "z_pred_count_df_mnb = tuned_count_df_nb_clf.fit(X_train_count_df_vec, z_train).predict(X_test_count_df_vec)\n",
        "z_pred_tfidf_df_mnb = tuned_tfidf_df_nb_clf.fit(X_train_tfidf_df_vec, z_train).predict(X_test_tfidf_df_vec)\n",
        "count_cm_mnb = confusion_matrix(z_test, z_pred_count_mnb, labels = ['fake', 'real'])\n",
        "count_df_cm_mnb = confusion_matrix(z_test, z_pred_count_df_mnb, labels = ['fake', 'real'])\n",
        "tfidf_cm_mnb = confusion_matrix(z_test, z_pred_tfidf_mnb, labels = ['fake', 'real'])\n",
        "tfidf_df_cm_mnb = confusion_matrix(z_test, z_pred_tfidf_df_mnb, labels = ['fake', 'real'])\n",
        "print(count_cm_mnb)\n",
        "print(count_df_cm_mnb)\n",
        "print(tfidf_cm_mnb)\n",
        "print(tfidf_df_cm_mnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBDiLJt0p9eR",
        "outputId": "caca9263-9fec-4b3a-8702-d666673b7f0c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5 5]\n",
            " [3 5]]\n",
            "[[4 6]\n",
            " [2 6]]\n",
            "[[5 5]\n",
            " [3 5]]\n",
            "[[5 5]\n",
            " [3 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(z_test, z_pred_count_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_count_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_count_df_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_count_df_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_mnb, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_df_mnb, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_df_mnb, average = None))\n",
        "print()\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['fake', 'real']\n",
        "print(classification_report(z_test, z_pred_count_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_count_df_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_df_mnb, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_mnb, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSer5a-4TNTa",
        "outputId": "3babab17-4a8f-4adf-eb6a-bd547c3d9146"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "[0.66666667 0.5       ]\n",
            "[0.4  0.75]\n",
            "\n",
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "[0.625 0.5  ]\n",
            "[0.5   0.625]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.40      0.50        10\n",
            "        true       0.50      0.75      0.60         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.58      0.57      0.55        18\n",
            "weighted avg       0.59      0.56      0.54        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.50      0.56        10\n",
            "        true       0.50      0.62      0.56         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.56      0.56      0.56        18\n",
            "weighted avg       0.57      0.56      0.56        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM"
      ],
      "metadata": {
        "id": "J4G-D7sup_ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the SVC models\n",
        "count_svm_clf = SVC()\n",
        "tfidf_svm_clf = SVC()\n",
        "count_df_svm_clf = SVC()\n",
        "tfidf_df_svm_clf = SVC()\n",
        "\n",
        "# use the training data to train the SVM model\n",
        "count_svm_clf.fit(X_train_count_vec, z_train)\n",
        "count_df_svm_clf.fit(X_train_count_df_vec, z_train)\n",
        "tfidf_svm_clf.fit(X_train_tfidf_vec, z_train)\n",
        "tfidf_df_svm_clf.fit(X_train_tfidf_df_vec, z_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8TUELIAqDKB",
        "outputId": "a5fb99e2-972f-4c4a-8b15-a3fd2e5565f0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test the SVM classifier"
      ],
      "metadata": {
        "id": "CVB2np3CX8nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "print(count_svm_clf.score(X_test_count_vec, z_test))\n",
        "print(count_df_svm_clf.score(X_test_count_df_vec, z_test))\n",
        "print(tfidf_svm_clf.score(X_test_tfidf_vec, z_test))\n",
        "print(tfidf_df_svm_clf.score(X_test_tfidf_df_vec, z_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEq1ORJ6X3Fe",
        "outputId": "99c76c07-63ac-49df-8f9d-42d7acc65a7b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4444444444444444\n",
            "0.3888888888888889\n",
            "0.5555555555555556\n",
            "0.4444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "z_pred_count_svm = count_svm_clf.fit(X_train_count_vec, z_train).predict(X_test_count_vec)\n",
        "z_pred_tfidf_svm = tfidf_svm_clf.fit(X_train_tfidf_vec, z_train).predict(X_test_tfidf_vec)\n",
        "z_pred_count_df_svm = count_df_svm_clf.fit(X_train_count_df_vec, z_train).predict(X_test_count_df_vec)\n",
        "z_pred_tfidf_df_svm = tfidf_df_svm_clf.fit(X_train_tfidf_df_vec, z_train).predict(X_test_tfidf_df_vec)\n",
        "count_cm_svm = confusion_matrix(z_test, z_pred_count_svm, labels = ['fake', 'real'])\n",
        "count_df_cm_svm = confusion_matrix(z_test, z_pred_count_df_svm, labels = ['fake', 'real'])\n",
        "tfidf_cm_svm = confusion_matrix(z_test, z_pred_tfidf_svm, labels = ['fake', 'real'])\n",
        "tfidf_df_cm_svm = confusion_matrix(z_test, z_pred_tfidf_df_svm, labels = ['fake', 'real'])\n",
        "print(count_cm_svm)\n",
        "print(count_df_cm_svm)\n",
        "print(tfidf_cm_svm)\n",
        "print(tfidf_df_cm_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nJ_2vycYFuQ",
        "outputId": "5fa7853e-a7a0-4fd5-fa45-e0b302b3483b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 8]\n",
            " [2 6]]\n",
            "[[2 8]\n",
            " [3 5]]\n",
            "[[4 6]\n",
            " [2 6]]\n",
            "[[4 6]\n",
            " [4 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(z_test, z_pred_count_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_count_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_count_df_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_count_df_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_df_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_df_svm, average = None))\n",
        "print()\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['fake', 'real']\n",
        "print(classification_report(z_test, z_pred_count_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_count_df_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_df_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx7lDE2iesR0",
        "outputId": "f13c1b55-ddd0-48ed-897b-8c86e5e642e4"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5        0.42857143]\n",
            "[0.2  0.75]\n",
            "\n",
            "[0.4        0.38461538]\n",
            "[0.2   0.625]\n",
            "\n",
            "[0.66666667 0.5       ]\n",
            "[0.4  0.75]\n",
            "\n",
            "[0.5 0.4]\n",
            "[0.4 0.5]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.20      0.29        10\n",
            "        true       0.43      0.75      0.55         8\n",
            "\n",
            "    accuracy                           0.44        18\n",
            "   macro avg       0.46      0.47      0.42        18\n",
            "weighted avg       0.47      0.44      0.40        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.40      0.20      0.27        10\n",
            "        true       0.38      0.62      0.48         8\n",
            "\n",
            "    accuracy                           0.39        18\n",
            "   macro avg       0.39      0.41      0.37        18\n",
            "weighted avg       0.39      0.39      0.36        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.40      0.44        10\n",
            "        true       0.40      0.50      0.44         8\n",
            "\n",
            "    accuracy                           0.44        18\n",
            "   macro avg       0.45      0.45      0.44        18\n",
            "weighted avg       0.46      0.44      0.44        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.40      0.50        10\n",
            "        true       0.50      0.75      0.60         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.58      0.57      0.55        18\n",
            "weighted avg       0.59      0.56      0.54        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Error Analysis"
      ],
      "metadata": {
        "id": "PisrdIADgu0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69_VoAingMCs",
        "outputId": "dc07982c-dbf4-4b19-e634-e631c6bee68a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB error analysis\n",
            "positive examples that are mistakenly predicted as negative -\n",
            "\n",
            "'I like the Pizza at Dominoes for their special ingredients and the prices, they give out one of the best pizza\\'s in town. I ordered Special Pepperoni Pizza (large) from the online portal which gives me a discount of 50\\% for being a regular customer, they always provide a good quantity of cheese over the pizza, we generally do not need to add a topping of pizza cheese for cheese lovers compared to other places. The place has a nice ambient environment, it is generally empty as it has more delivery orders than dine in. Orders are processed very quickly and has a special taste to it. Cost friendly prices makes me pick it up as my best buy. Overall Rating : 5/5'\n",
            "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
            "'Carlo\\'s Plate Shack was amazing! The waitress was friendly, attentive, and helpful in answering any of our questions. We ordered a pitcher of fresh brewed iced tea, as well as loganberry milkshakes to start, along with the innovative pizza plate appetizer, which consists of a \\'dip\\' made of pizza sauce and chunks of various vegetables and meats, and fresh baked pizza dough pieces used to scoop up the toppings. All were delicious and well made with fresh ingredients. For dinner, we ordered the Southern Comfort Plate, the Buffalo Chicken Plate, and the Hawaiian Lunch Plate. All of the dishes were spins on the classic Rochester Garbage Plate, with a main meat, sauce/toppings, and 2 sides. The SoCo Plate had freshly fried chicken breast strips, laid on top of homemade mashed potatoes and mac and cheese, and covered in a Southern Comfort-based hot sauce, which was the icing on the cake so to speak. All of the dishes were amazing and along with the service and reasonable prices made for an amazing dining experience. We\\'ll be back for sure!'\n",
            "errors: 3\n",
            "\n",
            "negative examples that are mistakenly predicted as positive -\n",
            "\n",
            "errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Hypertuning parameters"
      ],
      "metadata": {
        "id": "EhSA_Uzlg0EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of possible parameters\n",
        "params_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel':['linear','rbf', 'poly'] }\n",
        "# Create the GridSearchCV object\n",
        "svm_count_grid_clf = GridSearchCV(count_svm_clf, params_grid)\n",
        "# print(grid_clf)\n",
        "# mnb_count_grid_clf = GridSearchCV(count_nb_clf, grid_params)\n",
        "svm_count_grid_clf.fit(X_train_count_vec, z_train)\n",
        "print(\"Best Score Count: \", svm_count_grid_clf.best_score_)\n",
        "print(\"Best Params Count: \", svm_count_grid_clf.best_params_)\n",
        "print()\n",
        "svm_tfidf_grid_clf = GridSearchCV(tfidf_svm_clf, params_grid)\n",
        "svm_tfidf_grid_clf.fit(X_train_tfidf_vec, z_train)\n",
        "print(\"Best Score tfidf: \", svm_tfidf_grid_clf.best_score_)\n",
        "print(\"Best Params tfidf: \", svm_tfidf_grid_clf.best_params_)\n",
        "print()\n",
        "svm_count_df_grid_clf = GridSearchCV(count_df_svm_clf, params_grid)\n",
        "svm_count_df_grid_clf.fit(X_train_count_df_vec, z_train)\n",
        "print(\"Best Score Count df: \", svm_count_df_grid_clf.best_score_)\n",
        "print(\"Best Params Count df: \", svm_count_df_grid_clf.best_params_)\n",
        "print()\n",
        "svm_tfidf_df_grid_clf = GridSearchCV(tfidf_df_svm_clf, params_grid)\n",
        "svm_tfidf_df_grid_clf.fit(X_train_tfidf_df_vec, z_train)\n",
        "print(\"Best Score Count: \", svm_tfidf_df_grid_clf.best_score_)\n",
        "print(\"Best Params Count: \", svm_tfidf_df_grid_clf.best_params_)\n",
        "# print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUO2bTi1g4FT",
        "outputId": "4b7cf37c-d18b-4dd7-8bd2-0200171b7149"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score Count:  0.5704761904761905\n",
            "Best Params Count:  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "\n",
            "Best Score tfidf:  0.5285714285714286\n",
            "Best Params tfidf:  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "\n",
            "Best Score Count df:  0.5295238095238094\n",
            "Best Params Count df:  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "\n",
            "Best Score Count:  0.4866666666666667\n",
            "Best Params Count:  {'C': 0.0001, 'gamma': 0.001, 'kernel': 'poly'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create and test tuned SVM models"
      ],
      "metadata": {
        "id": "9SRAQmimudV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the SVC models\n",
        "count_svm_clf = SVC(C = 1, gamma = 0.1, kernel = 'rbf')\n",
        "tfidf_svm_clf = SVC(C = 1, gamma = 1, kernel = 'rbf')\n",
        "count_df_svm_clf = SVC(C = 1, gamma = 1, kernel = 'rbf')\n",
        "tfidf_df_svm_clf = SVC(C = 0.0001, gamma = 0.001, kernel = 'poly')\n",
        "\n",
        "# use the training data to train the SVM model\n",
        "count_svm_clf.fit(X_train_count_vec, z_train)\n",
        "count_df_svm_clf.fit(X_train_count_df_vec, z_train)\n",
        "tfidf_svm_clf.fit(X_train_tfidf_vec, z_train)\n",
        "tfidf_df_svm_clf.fit(X_train_tfidf_df_vec, z_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYm0CNslqeL6",
        "outputId": "aee38661-e994-4c6c-b896-0493d3c8548b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.0001, gamma=0.001, kernel='poly')"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier on the test data set, print accuracy score\n",
        "\n",
        "print(count_svm_clf.score(X_test_count_vec, z_test))\n",
        "print(count_df_svm_clf.score(X_test_count_df_vec, z_test))\n",
        "print(tfidf_svm_clf.score(X_test_tfidf_vec, z_test))\n",
        "print(tfidf_df_svm_clf.score(X_test_tfidf_df_vec, z_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwBfx40GvW-T",
        "outputId": "44c06a64-8b44-4d86-b450-b8d522559d35"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5555555555555556\n",
            "0.6666666666666666\n",
            "0.5555555555555556\n",
            "0.3888888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print confusion matrix (row: ground truth; col: prediction)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "z_pred_count_svm = count_svm_clf.fit(X_train_count_vec, z_train).predict(X_test_count_vec)\n",
        "z_pred_tfidf_svm = tfidf_svm_clf.fit(X_train_tfidf_vec, z_train).predict(X_test_tfidf_vec)\n",
        "z_pred_count_df_svm = count_df_svm_clf.fit(X_train_count_df_vec, z_train).predict(X_test_count_df_vec)\n",
        "z_pred_tfidf_df_svm = tfidf_df_svm_clf.fit(X_train_tfidf_df_vec, z_train).predict(X_test_tfidf_df_vec)\n",
        "count_cm_svm = confusion_matrix(z_test, z_pred_count_svm, labels = ['fake', 'real'])\n",
        "count_df_cm_svm = confusion_matrix(z_test, z_pred_count_df_svm, labels = ['fake', 'real'])\n",
        "tfidf_cm_svm = confusion_matrix(z_test, z_pred_tfidf_svm, labels = ['fake', 'real'])\n",
        "tfidf_df_cm_svm = confusion_matrix(z_test, z_pred_tfidf_df_svm, labels = ['fake', 'real'])\n",
        "print(count_cm_svm)\n",
        "print(count_df_cm_svm)\n",
        "print(tfidf_cm_svm)\n",
        "print(tfidf_df_cm_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHqEb6ZKvbnH",
        "outputId": "5f45b03b-7f26-412e-e512-fd296d135a47"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 6]\n",
            " [2 6]]\n",
            "[[7 3]\n",
            " [3 5]]\n",
            "[[4 6]\n",
            " [2 6]]\n",
            "[[4 6]\n",
            " [5 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# from sklearn.metrics import recall_score\n",
        "print(precision_score(z_test, z_pred_count_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_count_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_count_df_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_count_df_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_svm, average = None))\n",
        "print()\n",
        "print(precision_score(z_test, z_pred_tfidf_df_svm, average = None))\n",
        "print(recall_score(z_test, z_pred_tfidf_df_svm, average = None))\n",
        "print()\n",
        "# from sklearn.metrics import classification_report\n",
        "target_names = ['fake', 'real']\n",
        "print(classification_report(z_test, z_pred_count_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_count_df_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_df_svm, target_names = target_names))\n",
        "print(classification_report(z_test, z_pred_tfidf_svm, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHkvAaZqFHPH",
        "outputId": "3892a37b-3771-4726-a1a3-5ac46a510f50"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.66666667 0.5       ]\n",
            "[0.4  0.75]\n",
            "\n",
            "[0.7   0.625]\n",
            "[0.7   0.625]\n",
            "\n",
            "[0.66666667 0.5       ]\n",
            "[0.4  0.75]\n",
            "\n",
            "[0.44444444 0.33333333]\n",
            "[0.4   0.375]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.40      0.50        10\n",
            "        true       0.50      0.75      0.60         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.58      0.57      0.55        18\n",
            "weighted avg       0.59      0.56      0.54        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.70      0.70      0.70        10\n",
            "        true       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.66      0.66      0.66        18\n",
            "weighted avg       0.67      0.67      0.67        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.44      0.40      0.42        10\n",
            "        true       0.33      0.38      0.35         8\n",
            "\n",
            "    accuracy                           0.39        18\n",
            "   macro avg       0.39      0.39      0.39        18\n",
            "weighted avg       0.40      0.39      0.39        18\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.40      0.50        10\n",
            "        true       0.50      0.75      0.60         8\n",
            "\n",
            "    accuracy                           0.56        18\n",
            "   macro avg       0.58      0.57      0.55        18\n",
            "weighted avg       0.59      0.56      0.54        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out specific type of error for further analysis\n",
        "\n",
        "# print out the negative examples that are mistakenly predicted as positive\n",
        "# according to the confusion matrix, there should be 0 such examples\n",
        "print(\"MNB error analysis\")\n",
        "print(\"positive examples that are mistakenly predicted as negative -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'positive' and y_pred_mnb[i] == 'negative'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)\n",
        "\n",
        "# print out the positive examples that are mistakenly predicted as negative\n",
        "# according to the confusion matrix, there should be 2 such examples\n",
        "print()\n",
        "print(\"negative examples that are mistakenly predicted as positive -\")\n",
        "print()\n",
        "err_cnt = 0\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i] == 'negative' and y_pred_mnb[i] == 'positive'):\n",
        "        print(X_test[i])\n",
        "        err_cnt = err_cnt + 1\n",
        "print(\"errors:\", err_cnt)"
      ],
      "metadata": {
        "id": "-Rpk5MXOFM2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}